{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The third In-class-exercise (02/08/2022, 40 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPlease write you answer here:\\n\\nQuestion :- What is the review of Nokia 139 cm (55 inch) Ultra HD (4K) LED Smart Android TV with Sound by JBL  (55CAUHDN). \\nChecking the reviews of Nokia Tv and analysing it if we can purchase it or not.\\nReviews and Ratings are required to analyse the product which are given by customers who bought the TV who are using them or . We are using Flipkart website for checking the reviews and this contains the reviews and rating of the product. \\nWe can analyze the reviews by considering the words and rating out in them using some common words. \\n\\n\\nSteps for Collecting and Saving Data:\\nI have used the BeautifulSoup library to extract the information from the website.\\nI have extracted the reviews by using the classname and then appended to the empty list.\\nTo extract 1000 reviews I have itearted 40 times as each page contains 10 reviews and \\nI have generated the url dynamically while iterating\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
    "\n",
    "'''\n",
    "Please write you answer here:\n",
    "\n",
    "Question :- What is the review of Nokia 139 cm (55 inch) Ultra HD (4K) LED Smart Android TV with Sound by JBL  (55CAUHDN). \n",
    "Checking the reviews of Nokia Tv and analysing it if we can purchase it or not.\n",
    "Reviews and Ratings are required to analyse the product which are given by customers who bought the TV. We are using Flipkart website for checking the reviews and this contains the reviews and rating of the product. \n",
    "We can analyze the reviews by considering the words and rating out in them using some common words. \n",
    "\n",
    "\n",
    "Steps for Collecting and Saving Data:\n",
    "I have used the BeautifulSoup library to extract the information from the website.\n",
    "I have extracted the reviews by using the classname and then appended to the empty list.\n",
    "To extract 1000 reviews I have itearted 40 times as each page contains 10 reviews and \n",
    "I have generated the url dynamically while iterating\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data frame is 1010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glimpse of Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review from Technology Gyan: Almost everything...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pretty good</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>Nice product!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Glimpse of Review Full Review\n",
       "0     Review from Technology Gyan: Almost everything...           5\n",
       "1                                             Brilliant           5\n",
       "2                                   Best in the market!           5\n",
       "3                                           Pretty good           4\n",
       "4                                     Terrific purchase           5\n",
       "...                                                 ...         ...\n",
       "1005                                     Nice product!            5\n",
       "1006                                 Highly recommended           5\n",
       "1007                                     Simply awesome           5\n",
       "1008                                     Simply awesome           5\n",
       "1009                                          Excellent           5\n",
       "\n",
       "[1010 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "main_text = [] # List to store Review headings\n",
    "sub_text =[] #List to store reviews\n",
    "for number in range(102):\n",
    "  link = \"https://www.flipkart.com/nokia-139cm-55-inch-ultra-hd-4k-led-smart-android-tv-sound-jbl/p/itmffvfvyztsmfmq?pid=TVSFFVFVJEGZ3R5H&otracker=nmenu_sub_TVs%20%26%20Appliances_0_Nokia\" + str(number) # Generating link dynamically\n",
    "  page = requests.get(link) # Accessing the webpage\n",
    "  soup = BeautifulSoup(page.text, 'html.parser')\n",
    "  main_reviews = soup.find_all(class_='_2-N8zT') # Getting the Review Heading by using the class name\n",
    "  text_reviews = soup.find_all(class_='_3LWZlK _1BLPMq') # Getting the full reviews by using the class name\n",
    "  for ele, sub_ele in zip(main_reviews, text_reviews) : # Iterating through the list\n",
    "      main_text.append(ele.text) #Appending to empty list\n",
    "      sub_text.append(sub_ele.text)\n",
    "df = pd.DataFrame(list(zip(main_text, sub_text)), columns =['Glimpse of Review', 'Full Review'])  # Creating Dataframe\n",
    "print(\"Length of data frame is {0}\".format(len(df)))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
    "\n",
    "The following information of the article needs to be collected:\n",
    "\n",
    "(1) Title\n",
    "\n",
    "(2) Venue/journal/conference being published\n",
    "\n",
    "(3) Year\n",
    "\n",
    "(4) Authors\n",
    "\n",
    "(5) Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
    "\n",
    "The following information needs to be collected:\n",
    "\n",
    "(1) User_name\n",
    "\n",
    "(2) Posted time\n",
    "\n",
    "(3) Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "####input your credentials here\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "#####United Airlines\n",
    "# Open/Create a file to append data\n",
    "csvFile = open('ua.csv', 'a')\n",
    "#Use csv Writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,q=\"#unitedAIRLINES\",count=100,\n",
    "                           lang=\"en\",\n",
    "                           since=\"2017-04-03\").items():\n",
    "    print (tweet.created_at, tweet.text)\n",
    "    csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
